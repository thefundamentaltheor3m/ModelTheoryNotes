\section{A Crash Course on First-Order Logic}

\subsection{Languages and Structures}

We begin by recalling the notion of a first-order language.

\begin{boxdefinition}[Language]
    A \textbf{language} is a disjoint union
    \begin{align*}
        \Lang = \Funcs \cup \Rels \cup \Consts
    \end{align*}
    of countable sets of symbols, where
    \begin{itemize}
        \item $\Funcs$ is a set of function symbols
        \item $\Rels$ is a set of relation symbols
        \item $\Consts$ is a set of constant symbols
    \end{itemize}
\end{boxdefinition}

Next, we recall the notion of a structure in a language.

\begin{boxdefinition}[Structure]
    Let $\Lang$ be a structure. An \textbf{$\Lang$-structure} is a tuple
    \begin{align*}
        M = \cycl{U; F, R, C}
    \end{align*}
    consisting of a non-empty set $U$ and functions, relations, and constants that live in $\Funcs$, $\Rels$ and $\Consts$ respectively. $U$ known as the \textbf{universe} of $M$, and is denoted by $\abs{M}$. The function, relation and constant symbols of $M$ are denoted $F^M$, $R^M$ and $C^M$ respectively.
\end{boxdefinition}

Any function or relation in a structure has an \textbf{arity}, which is informally the number of arguments it takes. An important fact to note is that arities are not a feature of functions and relations themselves, but of their corresponding \textit{symbols}. In other words, \textbf{arity is a syntactic notion}. Semantically speaking, when we seek an interpretation of a function symbol of some arity $n$, we are forced to limit our search to the set of functions from $U^n$ to $U$.

We now describe the notion of structure-preserving bijections, known as isomorphisms.\todo{MAKE MORE PRECISE - FOLLOW DEF 2.9 IN BOOK}

\begin{boxdefinition}[Isomorphism]\label{Ch1:Def:Isomorphism}
    Let $\Lang$ be a language and let $M, N$ be $\Lang$-structures. We say that a function $g : \abs{M} \to \abs{N}$ is an \textbf{isomorphism} if
    \begin{enumerate}
        \item $g$ is a bijection
        \item ``$g$ commutes with functions''
        \item ``$g$ commutes with relations''
        \item ``$g$ agrees on constants''
    \end{enumerate}
    where the double-quotes for the second and third point above refer to the fact that we implicitly require an equality of arities condition before we can talk about composing isomorphisms with multi-ary functions.
\end{boxdefinition}

% Lecture 2

We are now ready to define submodels.

\begin{boxdefinition}[Submodel]
    Let $M, N$ be $\Lang$-structures. We say that $M$ is a submodel of $N$, denoted $M \subseteq N$, if
    \begin{enumerate}
        \item $\abs{M} \subseteq \abs{N}$.
        \item For all function symbols $F\of{x_1, \ldots, x_n}$, the interpretation in $M$ agrees with the interpretation in $N$.
        \item For all relation symbols $R\of{a_1, \ldots, a_n}$, the interpretation in $M$ agrees with the interpretation in $N$.
        \item For all constant symbols $C$, the interpretation in $M$ agrees with the interpretation in $N$.
    \end{enumerate}
\end{boxdefinition}

In particular, a submodel of a model is also a model. For instance, if $G$ is a group, ie, a model of the group axioms, then any submodel of $G$ is, in fact, a subgroup of $G$, and a group in its own right (in that it again models the group axioms).

We now talk about more syntactic elements of a language.

\subsection{Syntax: Terms, Formulae, Sentences and Theories}

\begin{boxdefinition}[Terms]\label{Ch1:Def:Term}
    Let $\Lang$ be a language. $\Term(\Lang)$ is defined to be the minimal set of finite sequences of symbols\footnote{Here, the set of variable symbols is countable, but we might, on occasion, need uncountably many variable symbols} from
    \begin{align*}
        \set{(, ), [, ]} \cup \Consts \cup \Funcs \cup \set{x_1, x_2, x_3, \ldots}
    \end{align*}
    satisfying the following rules:
    \begin{enumerate}
        \item Every constant symbol is a term.
        \item Every variable is a term.
        \item For all $n$-ary functions $f$ and $n$ terms $t_1, \ldots, t_n$, $f\of{t_1, \ldots, t_n}$ is a term.
        \item Every term arises in this way.
    \end{enumerate}
\end{boxdefinition}
\begin{remark}%? do you mind if I write in remarks? you can delete them later
    In other words, the elements of $\Term(\Lang)$ are exactly the constants, variables, and functions of such (constants and variables).
\end{remark}

Recall, from \Cref{Ch1:Def:Isomorphism}, that isomorphisms are, in particular, bijections that agree on constants. It is possible to show that they also agree on the interpretations of terms in models. We will show this later.

% For an ULTRA-FORMAL presentation of the material, look at D. Monk Mathematical Logic, Springer GTM. But Rami's feedback is: an undergraduate cannot follow it because it is too technical, and a graduate student will find that it has too much detail but not much actual content.

In similar fashion, we can define the formulae in a language.

\begin{boxdefinition}[Formulae]
    Let $\Lang$ be a language. $\Fml(\Lang)$ is defined to be the minimal set of finite sequences of symbols from
    \begin{align*}
        \Term\of{L} \cup \set{\land, \lor, \to, \neg, \ldots} \cup \set{=} \cup \set{\forall, \exists}
    \end{align*}
    satisfying the following rules:
    \begin{enumerate}
        \item For all $\tau_1, \tau_2 \in \Term\of{\Lang}$, $\tau_1 = \tau_2$ is a formula.
        \item For all $n$-ary relations $R$ and $n$ terms $t_1, \ldots, t_n$, $R\of{t_1, \ldots, t_n}$ is a formula.
        \item For all connectives $\star$ and formulae $\Phi$ and $\Psi$, $\Phi \star \Psi$ is a formula.
        \item For a quantifier $Q$, variable $x$ and formula $\varphi(x)$, $Qx \parenth{\varphi\of{x}}$ is a formula.
        \item Every formula arises in this way.
    \end{enumerate}
    Formulae consisting only of a single relation symbol (including formulae that only consist of an equality) are called \textbf{atomic formulae}. The atomic formulae of $\Lang$ are denoted $\AFml(\Lang)$.
\end{boxdefinition}

For a formula $\varphi$, denote by $\FV{\varphi}$ the set of free variables of $\varphi$. It is sometimes useful to distinguish those formulae in a language that contain no free variables.

\begin{boxdefinition}
    Define the set of \textbf{sentences} of a language $\Lang$ to be
    \begin{align*}
        \Sent\of{\Lang} := \setst{\varphi \in \Fml\of{\Lang}}{\FV{\varphi} = \emptyset}
    \end{align*}
\end{boxdefinition}

Essentially, a formula with no free variables is called a sentence. A theory is simply a set of sentences.

\begin{boxdefinition}[Theory]
    Let $\Lang$ be a language. An $\Lang$-theory is any subset $T \subseteq \Sent(\Lang)$.
\end{boxdefinition}

There are many well-known theories in mathematics. The most familiar examples come from algebra.

\begin{boxexample}[The Theory of Fields]\label{Ch1:Eg:Thy_of_Fields}
    The theory of fields is a first-order theory in the language of fields. This is a language with function symbols $+, \times, \inv$, relation symbol $=$, and constant symbols $0$ and $1$. It also has other first-order symbols, such as quantifiers, connectives and punctuation, but we ignore these (indeed, we will always take for granted that these exist). The theory of fields consists of the following sentences in this language:
    \begin{enumerate}
        \item $\forall x \forall y \forall z \brac{\parenth{x + y} + z = x + \parenth{y + z}}$
        \item $\forall x \forall y \brac{x + y = y + x}$
        \item $\forall x \exists y \brac{x + y = 0} \land \forall x \brac{x + 0 = x}$
        \item $\forall x \brac{x \neq 0 \to \exists y \brac{x y = 1}}$, where $\neq$ is the obvious shorthand
        \item $\forall x \brac{x \times 1 = x}$
        \item $\forall x \forall y \forall z \brac{x \times \parenth{y + z} = x \times y + x \times z}$
    \end{enumerate}
    Collectively, these sentences are known as the \textbf{theory of fields}.
\end{boxexample}

There are numerous well-known examples of fields. There is the question of how we can formally describe what it means for some structure, such as the rational numbers, to \textit{satisfy} the above sentences. To that end, we introduce the semantics of interpretation, namely, the notion of \textbf{satisfaction}.

\subsection{Semantics: Satisfaction}

We begin with the most important definition of this entire section.

\begin{boxdefinition}[Satisfaction - Sentences]
    Let $\Lang$ be a language and $M$ an $\Lang$-structure. For any $\varphi \in \Fml\of{\Lang}$, we say that \textbf{$M$ models $\varphi$}, denoted $M \models \varphi$, if \sorry % This is soooo tedious fr
\end{boxdefinition}

\begin{remark} % Move this to after the definition of satisfaction for sentences (once you finish). Thanks!!
     We note that, (a) $M \vDash \forall x \varphi(x)\iff N \vDash \neg \exists x \neg \varphi(x)$ and (b) $M \vDash \exists x \varphi(x) \iff M \vDash \neg \forall x \neg \varphi(x)$. This is worthy of note as for proofs, we will often need to induct on (the number of symbols in) formulas - just as we only need the logical connectives $\neg, \vee$ to get the rest, we only need to check satisfcation for a single quantifier and $\neg$.
\end{remark} % sure (thank you!)

We can define satisfaction for theories in the obvious way.

\begin{boxdefinition}[Satisfaction - Theories]
    Let $\Lang$ be a language and $M$ an $\Lang$-structure. Given an $\Lang$-theory $T$, we say that $M \models T$ if $M \models \psi$ for all $\psi \in T$.
\end{boxdefinition}

We are now ready to state a simple-sounding but rather non-trivial result.

\begin{boxlemma}
    Suppose $M$ and $N$ are both $\Lang$-structures. If $M \subseteq N$, then for all $\tau \in \Term\of{\Lang}$, $\tau^{M}\!\brac{a} = \tau^N\!\brac{a}$, where $a \in \abs{M} \times \cdots \times \abs{M}$ and $\tau^M\!\brac{a}$ and $\tau^N\!\brac{a}$ denote interpretations of $\tau$ in $M$ and $N$ with the variables all being interpreted as the components of $a$.
\end{boxlemma}

We do not prove this result. It is not difficult.

Next is a less trivial result.

\begin{boxlemma}
    If $M \subseteq N$, then $M \models \varphi$ if and only if $N \models \varphi$ for all quantifier-free formulae $\varphi$.
\end{boxlemma}


Going back to \Cref{Ch1:Eg:Thy_of_Fields}, we can now say the following.

\begin{boxexample}[Models of the Theory of Fields]
    Recall the theory of fields, seen in \Cref{Ch1:Eg:Thy_of_Fields}. It can be shown that the following structures in the language of fields satisfy the theory of fields:
    \begin{align*}
        \Q, \R, \C, \quotient{\Z}{7\Z}
    \end{align*}
    A model of the theory of fields is known simply as a \textbf{field}. We all know that this is an incredibly rich theory. It might have been even richer if Évariste Galois had had better control over his faculties...
\end{boxexample}

\subsection{Elementary Equivalence}

Recall the definition of an isomorphism of structures (\Cref{Ch1:Def:Isomorphism}). We can regard isomorphism as a \textit{syntactic} notion of equivalence of structures. In this subsection, we explore a \textit{semantic} notion of equivalence of models.

\begin{boxdefinition}[Elementary Equivalence]
    Let $\Lang$ be a langauge and let $M$ and $N$ be $\Lang$-structures. We say \textbf{$M$ is elementarily equivalent to $N$} if for every sentence $\varphi \in \Sent\of{\Lang}$, we have that $M$ satisfies $\varphi$ if and only if $N$ satisfies $\varphi$. We denote this
    \begin{align*}
        M \equiv N
    \end{align*}
\end{boxdefinition}

We can now relate isomorphisms to equivalence in the following manner.

\begin{boxtheorem}
    Let $\Lang$ be a language and let $M$ and $N$ be $\Lang$-structures. If $M \cong N$, then for every $\varphi\of{x_1, \ldots, x_n} \in \Fml\of{\Lang}$ and every $a_1, \ldots, a_n \in \abs{M}$, we have that
    \begin{align*}
        M \models \varphi\!\brac{a_1, \ldots, a_n}
        \iff 
        N \models \varphi\!\brac{f\of{a_1}, \ldots, f\of{a_n}}
    \end{align*}
\end{boxtheorem}
\begin{proof}
    Fix a formula $\varphi\of{x_1, \ldots, x_n} \in \Fml\of{\Lang}$ with $n$ free variables. We prove the result by performing induction\footnote{That is, cases} on $\varphi$.
    
    Suppose $\varphi$ is atomic. Then, there are two cases.
    \begin{itemize}
        \item \underline{$\varphi\of{x_1, \ldots, x_n}$ is of the form $\tau_1\of{x_1, \ldots, x_n} = \tau_2\of{x_1, \ldots, x_n}$ for terms $\tau_, \tau_2 \in \Term\of{\Lang}$.}
        In this case, it is possible to show, by cases on what $\tau_1$ and $\tau_2$ can be (see \Cref{Ch1:Def:Term}) that $f$ is compatible with $\varphi$.

        \item \underline{$\varphi$ is of the form $R\of{x_1, \ldots, x_n}$ for some $R \in \Rels\of{\Lang}$.}
        This is true by definition of an isomorphism (see \Cref{Ch1:Def:Isomorphism}).
    \end{itemize}

    Suppose, now, that $\varphi$ is not atomic. It is enough to show that the result shows if $\varphi$ is of the form $\psi_1\of{x_1, \ldots, x_n} \land \psi_2\of{x_1, \ldots, x_n}$, $\psi_1\of{x_1, \ldots, x_n} \lor \psi_2\of{x_1, \ldots, x_n}$, $\neg \psi\of{x_1, \ldots, x_n}$, and $\forall x_1 \forall x_2 \ldots \forall x_{n} \psi\of{x_1, \ldots, x_n}$, as these would be adequate.

    \begin{itemize}
        \item \underline{$\varphi$ is of the form $\psi_1\of{x_1, \ldots, x_n} \land \psi_2\of{x_1, \ldots, x_n}$.}
        This is immediate from the definition of satisfaction: for all $a_1, \ldots, a_n \in \abs{M}$, we have that
        \begin{align*}
            M \models \varphi\!\brac{a_1, \ldots, a_n}
            & \iff
            M \models \psi_1\!\brac{a_1, \ldots, a_n}
            \text{ and }
            M \models \psi_2\!\brac{a_1, \ldots, a_n} \\
            & \iff
            N \models \psi_1\!\brac{f\of{a_1}, \ldots, f\of{a_n}}
            \text{ and }
            N \models \psi_2\!\brac{f\of{a_1}, \ldots, f\of{a_n}} \\
            &\iff
            N \models \varphi\!\brac{f\of{a_1}, \ldots, f\of{a_n}}
        \end{align*}
        as required.

        \item \underline{$\varphi$ is of the form $\psi_1\of{x_1, \ldots, x_n} \lor \psi_2\of{x_1, \ldots, x_n}$.}
        Similar.

        \item \underline{$\varphi$ is of the form $\neg \psi\of{x_1, \ldots, x_n}$.}
        \sorry

        \item \underline{$\varphi$ is of the form $\exists x_1, \psi\of{x_1, \ldots, x_n}$.}\footnote{This is enough because you can induct on the number of free variables, with exactly this being the inductive step.}
        Fix $a_1, \ldots, a_n \in \abs{M}$. Then,
        \begin{align*}
            M \models \varphi\!\brac{a_1, \ldots, a_n}
            &\iff
            M \models \exists x \varphi\!\brac{x, a_2, \ldots, a_n} \\
            &\iff
            \text{There is some } a \in \abs{M} \text{ such that } M \models \varphi\!\brac{b, a_2, \ldots, a_n} \\
            &\iff \text{There is some } a \in \abs{M} \text{ such that } N \models \varphi\!\brac{f\of{b}, f\of{a_2}, \ldots, f\of{a_n}} \\
            &\iff \text{There is some } b \in \abs{N} \text{ such that } N \models \varphi\!\brac{b, f\of{a_2}, \ldots, f\of{a_n}} \\
            &\iff N \models \exists y \varphi\!\brac{y, f\of{a_2}, \ldots, f\of{a_n}}
        \end{align*}
        where we note that the `$\implies$' direction of the fourth $\iff$ comes from taking $b = f(a)$ and the `$\impliedby$' direction comes from the fact that $f$ is surjective, meaning that we can take $a$ to be any element of $\abs{M}$ such that $f(a) = b$.
    \end{itemize}
    We can conclude by noting that the above cases are adequate. See \sorry. % Mention remark about adequacy.
\end{proof}

\begin{boxcorollary}
    Let $\Lang$ be a language and let $M$ and $N$ be $\Lang$-structures. If $M \cong N$, then $M \equiv N$.
\end{boxcorollary}
\begin{proof}
    Let $f : M \iso N$ be an isomorphism from $M$ to $N$. \sorry
    % We argue, by induction on sentences, that $M \models \varphi \iff N \models \varphi$ for all $\varphi \in \Sent\of{\Lang}$. \sorry % Need to do this - not done in 
\end{proof}

\begin{boxwarning}
    The notion of isomorphism is (much?) finer than elementary equivalence.
\end{boxwarning} % Add counter-example from Cori-Lascar

We end our discourse on first-order logic by briefly discussing the theory of deduction and proof.

\subsection{Deduction and Proof}

Let $\Lang$ be a language. Recall that $\Sent\of{\Lang}$ is the set of \textit{sentences} in $\Lang$. Throughout this subsection, fix a theory $T \subseteq \Sent\of{\Lang}$.

\begin{boxdefinition}[Provability]
    We say a sentence $\varphi \in \Sent\of{\Lang}$ is \textbf{provable from $T$}, denoted $T \vdash \varphi$, if there exists a sequence $\cycl{\varphi_1, \ldots, \varphi_n}$ of $\Lang$-sentences such that $\varphi_n = \varphi$ and for all $i < n$, either $\varphi_i \in T$ or $\varphi_{i}$ is obtained from $\cycl{\varphi_1, \ldots, \varphi_{i - 1}}$ via the standard deduction rules of first-order logic, namely, Modus Ponens and Generalisation.
\end{boxdefinition}

We can say something about what makes $T$ a ``sensible'' set from which to deduce things.

\begin{boxdefinition}[Consistency]
    We say that $T$ is \textbf{consistent} if there is no $\varphi \in \Sent\of{\Lang}$ such that $T \vdash \varphi$ and $T \vdash \neg\varphi$.
\end{boxdefinition}

Consistency is equivalent to model existence.

\begin{boxtheorem}[Gödel-Henkin]
    $T$ is consistent if and only if there is an $\Lang$-structure $M$ such that $M \models T$.
\end{boxtheorem}

We do not prove this theorem here, but we will make extensive use of it.

We end by recalling the compactness theorem for first-order logic.

\begin{boxtheorem}[Compactness, Gödel-Malcev]
    If for any finite $T_0 \subseteq T$, there is a 
\end{boxtheorem}

We now discuss the \textit{size} of a model and a theory.