\section{A Crash Course on First-Order Logic}

\subsection{Languages and Structures}

We begin by recalling the notion of a first-order language.

\begin{boxdefinition}[Language]
    A \textbf{language} is a disjoint union
    \begin{align*}
        \Lang = \Funcs \cup \Rels \cup \Consts
    \end{align*}
    of countable sets of symbols, where
    \begin{itemize}
        \item $\Funcs$ is a set of function symbols
        \item $\Rels$ is a set of relation symbols
        \item $\Consts$ is a set of constant symbols
    \end{itemize}
\end{boxdefinition}

Next, we recall the notion of a structure in a language.

\begin{boxdefinition}[Structure]
    Let $\Lang$ be a structure. An \textbf{$\Lang$-structure} is a tuple
    \begin{align*}
        M = \cycl{U; F, R, C}
    \end{align*}
    consisting of a non-empty set $U$ and functions, relations, and constants that live in $\Funcs$, $\Rels$ and $\Consts$ respectively. $U$ known as the \textbf{universe} of $M$, and is denoted by $\abs{M}$. The function, relation and constant symbols of $M$ are denoted $F^M$, $R^M$ and $C^M$ respectively.
\end{boxdefinition}

Any function or relation in a structure has an \textbf{arity}, which is informally the number of arguments it takes. An important fact to note is that arities are not a feature of functions and relations themselves, but of their corresponding \textit{symbols}. In other words, \textbf{arity is a syntactic notion}. Semantically speaking, when we seek an interpretation of a function symbol of some arity $n$, we are forced to limit our search to the set of functions from $U^n$ to $U$.

We now describe the notion of structure-preserving bijections, known as isomorphisms.

\begin{boxdefinition}[Isomorphism]
    Let $\Lang$ be a language and let $M, N$ be $\Lang$-structures. We say that a function $g : \abs{M} \to \abs{N}$ is an \textbf{isomorphism} if
    \begin{enumerate}
        \item $g$ is a bijection
        \item ``$g$ commutes with functions''
        \item ``$g$ commutes with relations''
    \end{enumerate}
    where the double-quotes for the second and third point above refer to the fact that we implicitly require an equality of arities condition before we can talk about composing isomorphisms with multi-ary functions.
\end{boxdefinition}

% Lecture 2

We are now ready to define submodels.

\begin{boxdefinition}[Submodel]
    Let $M, N$ be $\Lang$-structures. We say that $M$ is a submodel of $N$, denoted $M \subseteq N$, if
    \begin{enumerate}
        \item $\abs{M} \subseteq \abs{N}$.
        \item For all function symbols $F\of{x_1, \ldots, x_n}$, the interpretation in $M$ agrees with the interpretation in $N$.
        \item For all relation symbols $R\of{a_1, \ldots, a_n}$, the interpretation in $M$ agrees with the interpretation in $N$.
        \item For all constant symbols $C$, the interpretation in $M$ agrees with the interpretation in $N$.
    \end{enumerate}
\end{boxdefinition}

In particular, a submodel of a model is also a model. For instance, if $G$ is a group, ie, a model of the group axioms, then any submodel of $G$ is, in fact, a subgroup of $G$, and a group in its own right (in that it again models the group axioms).

We now talk about more syntactic elements of a language.

\subsection{Syntax: Terms, Formulae, Sentences and Theories}

\begin{boxdefinition}[Terms]
    Let $\Lang$ be a language. $\Term(\Lang)$ is defined to be the minimal set of finite sequences of symbols\footnote{Here, the set of variable symbols is countable, but we might, on occasion, need uncountably many variable symbols} from
    \begin{align*}
        \set{(, ), [, ]} \cup \Consts \cup \Funcs \cup \set{x_1, x_2, x_3, \ldots}
    \end{align*}
    satisfying the following rules:
    \begin{enumerate}
        \item Every constant symbol is a term.
        \item Every variable is a term.
        \item For all $n$-ary functions $f$ and $n$ terms $t_1, \ldots, t_n$, $f\of{t_1, \ldots, t_n}$ is a term.
        \item Every term arises in this way.
    \end{enumerate}
\end{boxdefinition}

% For an ULTRA-FORMAL presentation of the material, look at D. Monk Mathematical Logic, Springer GTM. But Rami's feedback is: an undergraduate cannot follow it because it is too technical, and a graduate student will find that it has too much detail but not much actual content.

In similar fashion, we can define the formulae in a language.

\begin{boxdefinition}[Formulae]
    Let $\Lang$ be a language. $\Fml(\Lang)$ is defined to be the minimal set of finite sequences of symbols from
    \begin{align*}
        \Term\of{L} \cup \set{\land, \lor, \to, \neg, \ldots} \cup \set{=} \cup \set{\forall, \exists}
    \end{align*}
    satisfying the following rules:
    \begin{enumerate}
        \item For all $\tau_1, \tau_2 \in \Term\of{\Lang}$, $\tau_1 = \tau_2$ is a formula.
        \item For all $n$-ary relations $R$ and $n$ terms $t_1, \ldots, t_n$, $R\of{t_1, \ldots, t_n}$ is a formula.
        \item For all connectives $\star$ and formulae $\Phi$ and $\Psi$, $\Phi \star \Psi$ is a formula.
        \item For a quantifier $Q$, variable $x$ and formula $\varphi(x)$, $Qx \parenth{\varphi\of{x}}$ is a formula.
        \item Every formula arises in this way.
    \end{enumerate}
    Formulae consisting only of a single relation symbol (including formulae that only consist of an equality) are called \textbf{atomic formulae}. The atomic formulae of $\Lang$ are denoted $\AFml(\Lang)$.
\end{boxdefinition}

For a formula $\varphi$, denote by $\FV{\varphi}$ the set of free variables of $\varphi$. It is sometimes useful to distinguish those formulae in a language that contain no free variables.

\begin{boxdefinition}
    Define the set of \textbf{sentences} of a language $\Lang$ to be
    \begin{align*}
        \Sent\of{\Lang} := \setst{\varphi \in \Fml\of{\Lang}}{\FV{\varphi} = \emptyset}
    \end{align*}
\end{boxdefinition}

Essentially, a formula with no free variables is called a sentence. A theory is simply a set of sentences.

\begin{boxdefinition}[Theory]
    Let $\Lang$ be a language. An $\Lang$-theory is any subset $T \subseteq \Sent(\Lang)$.
\end{boxdefinition}

There are many well-known theories in mathematics. The most familiar examples come from algebra.

\begin{boxexample}[The Theory of Fields]\label{Ch1:Eg:Thy_of_Fields}
    The theory of fields is a first-order theory in the language of fields. This is a language with function symbols $+, \times, \inv$, relation symbol $=$, and constant symbols $0$ and $1$. It also has other first-order symbols, such as quantifiers, connectives and punctuation, but we ignore these (indeed, we will always take for granted that these exist). The theory of fields consists of the following sentences in this language:
    \begin{enumerate}
        \item $\forall x \forall y \forall z \brac{\parenth{x + y} + z = x + \parenth{y + z}}$
        \item $\forall x \forall y \brac{x + y = y + x}$
        \item $\forall x \exists y \brac{x + y = 0} \land \forall x \brac{x + 0 = x}$
        \item $\forall x \brac{x \neq 0 \to \exists y \brac{x y = 1}}$, where $\neq$ is the obvious shorthand
        \item $\forall x \brac{x \times 1 = x}$
        \item $\forall x \forall y \forall z \brac{x \times \parenth{y + z} = x \times y + x \times z}$
    \end{enumerate}
    Collectively, these sentences are known as the \textbf{theory of fields}.
\end{boxexample}

There are numerous well-known examples of fields. There is the question of how we can formally describe what it means for some structure, such as the rational numbers, to \textit{satisfy} the above sentences. To that end, we introduce the semantics of interpretation, namely, the notion of \textbf{satisfaction}.

\subsection{Semantics: Satisfaction}

We begin with the most important definition of this entire section.

\begin{boxdefinition}[Satisfaction - Sentences]
    Let $\Lang$ be a language and $M$ an $\Lang$-structure. For any $\varphi \in \Fml\of{\Lang}$, we say that \textbf{$M$ models $\varphi$}, denoted $M \models \varphi$, if \sorry % This is soooo tedious fr
\end{boxdefinition}

We can define satisfaction for theories in the obvious way.

\begin{boxdefinition}[Satisfaction - Theories]
    Let $\Lang$ be a language and $M$ an $\Lang$-structure. Given an $\Lang$-theory $T$, we say that $M \models T$ if $M \models \psi$ for all $\psi \in T$.
\end{boxdefinition}

We are now ready to state a simple-sounding but rather non-trivial result.

\begin{boxlemma}
    Suppose $M$ and $N$ are both $\Lang$-structures. If $M \subseteq N$, then for all $\tau \in \Term\of{\Lang}$, $\tau^{M}\!\brac{a} = \tau^N\!\brac{a}$, where $a \in \abs{M} \times \cdots \times \abs{M}$ and $\tau^M\!\brac{a}$ and $\tau^N\!\brac{a}$ denote interpretations of $\tau$ in $M$ and $N$ with the variables all being interpreted as the components of $a$.
\end{boxlemma}

We do not prove this result. It is not difficult.

Next is a less trivial result.

\begin{boxlemma}
    If $M \subseteq N$, then $M \models \varphi$ if and only if $N \models \varphi$ for all quantifier-free formulae $\varphi$.
\end{boxlemma}

Going back to \Cref{Ch1:Eg:Thy_of_Fields}, we can now say the following.

\begin{boxexample}[Models of the Theory of Fields]
    Recall the theory of fields, seen in \Cref{Ch1:Eg:Thy_of_Fields}. It can be shown that the following structures in the language of fields satisfy the theory of fields:
    \begin{align*}
        \Q, \R, \C, \quotient{\Z}{7\Z}
    \end{align*}
    A model of the theory of fields is known simply as a \textbf{field}. We all know that this is an incredibly rich theory. It might have been even richer if Évariste Galois had had better control over his faculties...
\end{boxexample}

We now discuss the \textit{size} of a model and a theory.

\subsection{Cardinality and Categoricity}

Throughout this subsection, let $\Lang$ be a language.

\begin{boxdefinition}[Cardinality of a Structure]
    Let $M$ be an $\Lang$-structure. The \textbf{cardinality of $M$}, denoted $\norm{M}$, is the cardinality of its universe $\abs{M}$.
\end{boxdefinition}

We can also talk about the size of a theory.

\begin{boxdefinition}[Categoricity of a Theory]\label{Ch1:Def:Categoricity}
    Let $T$ be an $\Lang$-theory. Suppose $\lambda \geq \abs{L}$ is a cardinal. We say that \textbf{$T$ is $\lambda$-Categorical}, or that \textbf{$T$ is categorical in $\lambda$}, if for all $\Lang$-structures $M$ and $N$ such that $M, N \models T$ and $\norm{M} = \norm{N} = \lambda$, we have that $M \cong N$.
\end{boxdefinition}

Categoricity brings up interesting questions, such as the so-called \textit{spectrum problem}. The spectrum of a theory with respect to a cardinal is defined as follows.

\begin{boxdefinition}[Spectrum]
    Let $T$ be an $\Lang$-theory and let $\lambda$ be a cardinal. We define the \textbf{spectrum of $T$ with respect to $\lambda$} to be
    \begin{align*}
        I\of{\lambda, T} := \abs{
            \setst{\quotient{M}{\cong}}{M \models T \text{ and } \norm{M} = \lambda}
        }
    \end{align*}
    ie, $I\of{\lambda, T}$ denotes the number of isomorphism classes of models of $T$ of cardinality $\lambda$.
\end{boxdefinition}

It is obvious, from \Cref{Ch1:Def:Categoricity}, that a theory $T$ is $\lambda$-categorical if and only if $I\of{\lambda, T} = 1$. However, if $T$ is not $\lambda$-categorical, then it is, in general, quite difficult to compute $I\of{\lambda, T}$. In fact, for most theories and cardinals, computing the spectrum is an \textit{open problem}, referred to as the \textbf{spectrum problem}.

There has been some progress on this problem. Steinitz made the following determinations.

\begin{boxtheorem}[Steinitz]
    Let $\Lang$ be the language of fields, and let $T$ be the theory of algebraically closed fields of characteristic $p$ (obtained by adding the appropriate sentences to the Theory of Fields encountered in \Cref{Ch1:Eg:Thy_of_Fields}). Then,
    \begin{enumerate}[label = \normalfont \arabic*.]
        \item $I\of{\aleph_{0}, T} = \aleph_{0}$.
        \item For all $\lambda > \aleph_{0}$, $I\of{\lambda, T} = 1$.
    \end{enumerate}
\end{boxtheorem}

The spectrum problem has been worked on by some of the most eminent logicians of our time, including Rami's advisor, Saharon Shelah, who proved a famous conjecture by Morley (1965). More on the Spectrum Problem can be found on the associated \href{https://en.wikipedia.org/wiki/Spectrum_of_a_theory#:~:text=More%20precisely%2C%20for%20any%20complete,of%20a%20countable%20theory%20T.}{Wikipedia page}, and while this is not the most authoritative source, its contents are nonetheless interesting.

Morley also proved a famous conjecture by Łos from the 1950s, which since became known as Morley's Categoricity Theorem.

\begin{boxtheorem}[Morley's Categoricity Theorem, Morley 1965]
    Let $T$ be a theory in a language $\Lang$. Assume that $\abs{\Lang} \leq \aleph_{0}$. If $\exists \lambda > \aleph_{0}$ such that $T$ is $\lambda$-categorical, them $\forall \lambda > \aleph_{0}$, $T$ is $\lambda$-categorical.
\end{boxtheorem}

One of our objectives in this course is to prove Morley's Categoricity Theorem.

As a side note, Morley was initially a PhD student of Saunders MacLane's at the University of Chicago. Morley didn't initially finish his PhD, to the point of losing his stipend at Chicago, but somehow landed a job at Berkeley, where he proved this famous theorem. MacLane, a staunch category theorist, didn't believe Morley's work was quite enough to merit a PhD; nevertheless, after being persuaded by the then-nascent (and very excited) model theory community, he eventually relented and awarded Morley his degree.